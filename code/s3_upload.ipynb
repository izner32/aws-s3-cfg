{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3 # access aws services\n",
    "import pandas as pd # creating dataframes\n",
    "import configparser # grabbing values of parameters for aws\n",
    "\n",
    "# for env \n",
    "import os \n",
    "from dotenv import load_dotenv \n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Grab values inside the config file \n",
    "#### 2. Create a dataframe out of it for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KEY</td>\n",
       "      <td>23424234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECRET</td>\n",
       "      <td>234234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Parameter     Value\n",
       "0       KEY  23424234\n",
       "1    SECRET    234234"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 \n",
    "config = configparser.ConfigParser() \n",
    "config.read_file(open('aws-s3.cfg')) \n",
    "\n",
    "KEY = os.getenv('AWS_KEY')\n",
    "SECRET = os.getenv('AWS_SECRET')\n",
    "\n",
    "# 2 \n",
    "pd.DataFrame({\n",
    "    \"Parameter\": [\"KEY\", \"SECRET\"],\n",
    "    \"Value\": [KEY,SECRET]\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "   's3',\n",
    "   region_name=\"us-west-2\",\n",
    "   aws_access_key_id=KEY,\n",
    "   aws_secret_access_key=SECRET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extract from source \n",
    "#### 2. Create S3 Bucket (folder)\n",
    "#### 3. Upload extracted data(objects/file) to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 \n",
    "data = [\"this\",\"is\",\"a\",\"sample\",\"data\"]\n",
    "\n",
    "# 2 \n",
    "sample_bucket = s3.create_bucket(\n",
    "    Bucket = 'bucket_name' \n",
    ")\n",
    "\n",
    "# 3 \n",
    "s3.upload_file(\n",
    "    'sample-path/data-is-here', # path of the file you wanted to upload \n",
    "    'bucket_name', # name of the bucket \n",
    "    'newfilename.csv' # file-name of the file you're uploading as they arrive into s3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. List Buckets(folder) \n",
    "#### 2. List Objects(file)\n",
    "#### 3. Delete Objects\n",
    "#### 4. Delete Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - List Buckets(folder)\n",
    "bucket_list = s3.list_buckets()[\"Buckets\"]\n",
    "bucket_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - List Objects(file)\n",
    "object_list = s3.list_objects(  \n",
    "    Bucket='sample_bucket', # from what bucket \n",
    "    MaxKeys=2, # show only two objects \n",
    "    Prefix='f') # passing it will limit the response to objects that start with the string we provided \n",
    "object_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Delete Objects\n",
    "s3.delete_object(  \n",
    "    Bucket='sample_bucket', # from what bucket  \n",
    "    Key='sample_data.csv' # what key of the object we wanted to delete \n",
    ")\n",
    "\n",
    "# check object list again\n",
    "object_list = s3.list_objects(  \n",
    "    Bucket='sample_bucket', # from what bucket \n",
    ")\n",
    "object_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Delete Buckets\n",
    "s3.delete_bucket('sample_bucket')\n",
    "\n",
    "# check bucket list again \n",
    "bucket_list = s3.list_buckets()[\"Buckets\"]\n",
    "bucket_list "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfb4883d108fc92ac768439090a2e92bb9a1f760a54beeecfd6762b5dcd70fe3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
